{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BrandonSchabell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see the input format for input_shape\n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Dense, \\\n",
    "    Flatten, Activation\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directory = os.getcwd() + os.sep + \"Images\"\n",
    "test_directory = os.getcwd() + os.sep + \"TestImages\"\n",
    "\n",
    "train_samples = 27992\n",
    "test_samples = 7000\n",
    "# train_samples = 33033\n",
    "# test_samples = 8254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to have to conv layers per each pooling but will take to long to run as of now\n",
    "# so far not looking like a very good model, it is not yet finished for me\n",
    "# would like to have more inputs on the first dense layer but also would take too long \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (5, 5), activation='relu', input_shape=(405,270, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(32, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(70, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 401, 266, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 133, 88, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 133, 88, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 129, 84, 32)       25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 43, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 39, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                233030    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 70)                4970      \n",
      "=================================================================\n",
      "Total params: 291,696\n",
      "Trainable params: 291,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27992 images belonging to 70 classes.\n",
      "Found 7000 images belonging to 70 classes.\n",
      "Epoch 1/50\n",
      "559/559 [==============================] - 103s 184ms/step - loss: 4.0541 - acc: 0.0395 - val_loss: 3.4522 - val_acc: 0.1466\n",
      "Epoch 2/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 3.2261 - acc: 0.1536 - val_loss: 2.6018 - val_acc: 0.3047\n",
      "Epoch 3/50\n",
      "559/559 [==============================] - 101s 180ms/step - loss: 2.6783 - acc: 0.2571 - val_loss: 2.2663 - val_acc: 0.3870\n",
      "Epoch 4/50\n",
      "559/559 [==============================] - 101s 180ms/step - loss: 2.3508 - acc: 0.3238 - val_loss: 2.0097 - val_acc: 0.4379\n",
      "Epoch 5/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 2.1448 - acc: 0.3700 - val_loss: 1.9164 - val_acc: 0.4656\n",
      "Epoch 6/50\n",
      "559/559 [==============================] - 101s 181ms/step - loss: 1.9910 - acc: 0.4038 - val_loss: 1.7994 - val_acc: 0.4923\n",
      "Epoch 7/50\n",
      "559/559 [==============================] - 101s 181ms/step - loss: 1.8935 - acc: 0.4253 - val_loss: 1.7815 - val_acc: 0.4939\n",
      "Epoch 8/50\n",
      "559/559 [==============================] - 101s 181ms/step - loss: 1.7801 - acc: 0.4564 - val_loss: 1.6869 - val_acc: 0.5256\n",
      "Epoch 9/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.6987 - acc: 0.4738 - val_loss: 1.6822 - val_acc: 0.5267\n",
      "Epoch 10/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.6300 - acc: 0.4910 - val_loss: 1.6938 - val_acc: 0.5261\n",
      "Epoch 11/50\n",
      "559/559 [==============================] - 100s 180ms/step - loss: 1.5702 - acc: 0.5065 - val_loss: 1.6902 - val_acc: 0.5246\n",
      "Epoch 12/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.5234 - acc: 0.5127 - val_loss: 1.6548 - val_acc: 0.5411\n",
      "Epoch 13/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.4841 - acc: 0.5278 - val_loss: 1.6850 - val_acc: 0.5390\n",
      "Epoch 14/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.4285 - acc: 0.5399 - val_loss: 1.6948 - val_acc: 0.5423\n",
      "Epoch 15/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.3903 - acc: 0.5485 - val_loss: 1.6945 - val_acc: 0.5391\n",
      "Epoch 16/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.3734 - acc: 0.5596 - val_loss: 1.6881 - val_acc: 0.5463\n",
      "Epoch 17/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.3182 - acc: 0.5697 - val_loss: 1.7303 - val_acc: 0.5441\n",
      "Epoch 18/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.3048 - acc: 0.5757 - val_loss: 1.7641 - val_acc: 0.5386\n",
      "Epoch 19/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.2800 - acc: 0.5791 - val_loss: 1.8091 - val_acc: 0.5373\n",
      "Epoch 20/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.2412 - acc: 0.5921 - val_loss: 1.7960 - val_acc: 0.5524\n",
      "Epoch 21/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.2008 - acc: 0.6031 - val_loss: 1.8286 - val_acc: 0.5447\n",
      "Epoch 22/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.1910 - acc: 0.6064 - val_loss: 1.8659 - val_acc: 0.5476\n",
      "Epoch 23/50\n",
      "559/559 [==============================] - 100s 179ms/step - loss: 1.1809 - acc: 0.6044 - val_loss: 1.8460 - val_acc: 0.5486\n",
      "Epoch 24/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.1444 - acc: 0.6197 - val_loss: 1.9493 - val_acc: 0.5497\n",
      "Epoch 25/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.1282 - acc: 0.6258 - val_loss: 1.8837 - val_acc: 0.5546\n",
      "Epoch 26/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.1113 - acc: 0.6260 - val_loss: 1.9074 - val_acc: 0.5527\n",
      "Epoch 27/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0989 - acc: 0.6334 - val_loss: 1.8874 - val_acc: 0.5490\n",
      "Epoch 28/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0862 - acc: 0.6352 - val_loss: 1.9727 - val_acc: 0.5459\n",
      "Epoch 29/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0656 - acc: 0.6405 - val_loss: 1.9558 - val_acc: 0.5560\n",
      "Epoch 30/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0591 - acc: 0.6457 - val_loss: 2.0316 - val_acc: 0.5489\n",
      "Epoch 31/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0300 - acc: 0.6507 - val_loss: 2.0739 - val_acc: 0.5536\n",
      "Epoch 32/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0288 - acc: 0.6515 - val_loss: 2.0399 - val_acc: 0.5543\n",
      "Epoch 33/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0275 - acc: 0.6549 - val_loss: 2.0152 - val_acc: 0.5549\n",
      "Epoch 34/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 1.0092 - acc: 0.6596 - val_loss: 2.0986 - val_acc: 0.5566\n",
      "Epoch 35/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9960 - acc: 0.6634 - val_loss: 2.1395 - val_acc: 0.5446\n",
      "Epoch 36/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9885 - acc: 0.6666 - val_loss: 2.0769 - val_acc: 0.5513\n",
      "Epoch 37/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9668 - acc: 0.6713 - val_loss: 2.1275 - val_acc: 0.5571\n",
      "Epoch 38/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9503 - acc: 0.6756 - val_loss: 2.1284 - val_acc: 0.5513\n",
      "Epoch 39/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9577 - acc: 0.6739 - val_loss: 2.1981 - val_acc: 0.5609\n",
      "Epoch 40/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9544 - acc: 0.6758 - val_loss: 2.1851 - val_acc: 0.5507\n",
      "Epoch 41/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9421 - acc: 0.6791 - val_loss: 2.1608 - val_acc: 0.5486\n",
      "Epoch 42/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9405 - acc: 0.6785 - val_loss: 2.1565 - val_acc: 0.5576\n",
      "Epoch 43/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9115 - acc: 0.6896 - val_loss: 2.2872 - val_acc: 0.5446\n",
      "Epoch 44/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9370 - acc: 0.6825 - val_loss: 2.2589 - val_acc: 0.5551\n",
      "Epoch 45/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.9000 - acc: 0.6935 - val_loss: 2.3429 - val_acc: 0.5493\n",
      "Epoch 46/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.8942 - acc: 0.6928 - val_loss: 2.2439 - val_acc: 0.5564\n",
      "Epoch 47/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.8936 - acc: 0.6951 - val_loss: 2.3569 - val_acc: 0.5519\n",
      "Epoch 48/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.8917 - acc: 0.6976 - val_loss: 2.2195 - val_acc: 0.5513\n",
      "Epoch 49/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.8878 - acc: 0.6978 - val_loss: 2.2981 - val_acc: 0.5466\n",
      "Epoch 50/50\n",
      "559/559 [==============================] - 99s 178ms/step - loss: 0.8818 - acc: 0.7001 - val_loss: 2.3333 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# would like to use more epochs but will take to long.\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 50\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size=(405, 270),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(405, 270),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_samples // batch_size,\n",
    "    epochs = 50,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = test_samples // batch_size)\n",
    "\n",
    "model.save_weights('starting_point.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict_generator(test_generator, test_samples // batch_size)\n",
    "predicted = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[3 0 0 ... 2 0 1]\n",
      " [1 0 1 ... 1 2 3]\n",
      " [4 3 1 ... 3 1 1]\n",
      " ...\n",
      " [2 0 1 ... 2 1 1]\n",
      " [0 0 1 ... 5 1 1]\n",
      " [4 2 1 ... 3 1 5]]\n",
      "0.011714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, predicted))\n",
    "\n",
    "print(accuracy_score(test_generator.classes, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
